# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Ответ:
**Kubernetes + ArgoCD + Jenkins + Ansible + Atlassian + Artifactory + HashiCorp Vault** <br />
**Kubernetes**: разворачивать в нем приложения как микросервисы через ArgoCD, который подтягивает конфигурацию, 
хранящуюся в гите; также использовать его в связке с Jenkins - динамические поды для сборок и тестов<br />
**ArgoCD**: CI/CD, запуск по коммиту в репозиторий с конфигами для кубера, автоматизация развертывания приложений из гита в 
кубер <br />
**Jenkins**: CI/CD, запуск по вебхуку гита (pull request, push), можно сделать параметры для каждой джобы, сами джобы 
сделать как pipelines и хранить их в гите, все пайплайны настраиваются под требования поставки; также есть 
возможность использовать в качестве агентов как динамические поды в кубере, так и отдельные машины с разными средами 
(с лицензируемым ПО, например); есть параллельный запуск джобов + можно сделать несколько дженкинсов под разные 
проекты; тесты также можно реализовать как пайплайны <br />
**Ansible**: если хостов, на которые нужно доставить приложение не много, то можно обойтись без Ansible (bash + jenkins 
groovy), но если надо раскатать на большое количество серверов, то лучше использовать ansible 
**Atlassian**: Bitbucket + Jira + Confluence - нет в задании, но очень полезны системы для отслеживания задачек Jira и 
для документации Confluence, к ним нужная по заданию система контроля версий Bitbucket, хорошо интегрируемая с 
системой для задачек (можно отслеживать коммиты по задачке)<br />
Artifactory: хранение поставок и докер образов (+ хелм чарты) + проксирование репозиториев, если закрытой контур 
на предприятии <br />
**HashiCorp Vault**: хранение секретов, можно обойтись секретами дженкинс, но для централизованного хранения лучше 
использовать Vault, особенно если один и тот же кред используется в нескольких системах, а не только в дженкинсе <br />

**Принцип взаимодействия**: в гит репозиторий запушили коммит -> BitBucket дергает вебхук дженкинса -> дженкинс делает 
поставку и запускает ее тесты, в зависимости от требуемого окружения в динамическом поде в кубере или на отдельной 
машине-агенте -> по ходу работы дженкинс с помощью плагинов ходит в Vault, BitBucket, Confluence и Artifactory для 
подтягивания доп кредов и пакетов/образов и запускает ansible playbooks -> после успешного прохождения тестирования 
дженкинс формирует поставку (docker image) и кладет ее в Artifactory, а также меняет конфигурацию ArgoCD на новый 
образ и еще добавляет настройки в часть с values, если нужно -> ArgoCD подхватывает изменения в гите и приводит 
развертку в кубере к желаемому состоянию <br />

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Ответ:
**Стек ELK**: ElasticSearch + Logstash + Kibana + Beats <br />
**Logstash** - сбор логов в центральное хранилище со всех хостов, обслуживающих систему; <br />
**Beats** - минимальные требования к приложениям, сбор логов из stdout; <br />
**ElasticSearch** закрывает требования по обработке логов - обеспечение поиска и фильтрации по записям логов <br />
**Kibana** - визуализация логов и взаимодействие с пользователями - обеспечение пользовательского интерфейса с 
возможностью предоставления доступа разработчикам для поиска по записям логов; возможность дать ссылку на сохранённый поиск по записям логов. <br />
Стек является активно развивающимся, довольно надежным и популярным проектом с открытым исходными кодом, по нему 
есть хорошая документация и большое количество кейсов использования <br />

**Взаимодействие**: Logstash собирает логи с целевых объектов, в том числе превращенных в такие объекты с помощью beats; 
ElasticSearch выполняет логику над хранилищем с логами, которое наполняет Logstash; Kibana предоставляет интерфейс 
для просмотра логов и взаимодействия с ElasticSearch

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.


Обоснуйте свой выбор.

## Ответ:
**Prometheus + Grafana** <br />
**Prometheus** удовлетворяет всем перечисленным требованиям + по нему много документации и под него написано много 
экспортеров + оптимизирован для работы в кубере (есть Prometheus Operator)<br />
**Grafana** затыкает запрос графического интерфейса, есть много готовых дашбордов + различные плагины, также ее 
дашборды можно хранить в гите (grafana as code)<br />

**Взаимодействие**: Prometheus сервер собирает выставленные метрики с exporter'ов (библиотек, sidecar и др.), складывает 
их в свою БД (TSDB); если настроены алерты, то Prometheus сервер отсылает сообщение с алертом на свой Alertmanager, 
который затем направляет сообщение с алертом на почту или в мессенджер (или другую систему). Графана использует 
Prometheus как источник данных для построения графиков

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
